{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional networks - ResNet\n",
    "\n",
    "A network with an architecure inspired by [ResNet](https://arxiv.org/pdf/1512.03385.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:02.724847Z",
     "start_time": "2020-08-15T08:04:02.708845Z"
    }
   },
   "outputs": [],
   "source": [
    "skip_training = False  # Set this flag to True before validation and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:08.347156Z",
     "start_time": "2020-08-15T08:04:03.114968Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import tools\n",
    "import tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:08.355059Z",
     "start_time": "2020-08-15T08:04:08.349056Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data directory is ../data\n"
     ]
    }
   ],
   "source": [
    "# When running on your own computer, you can specify the data directory by:\n",
    "# data_dir = tools.select_data_dir('/your/local/data/directory')\n",
    "data_dir = tools.select_data_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:08.365058Z",
     "start_time": "2020-08-15T08:04:08.357059Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select the device for training (use GPU if you have one)\n",
    "#device = torch.device('cuda:0')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:08.374061Z",
     "start_time": "2020-08-15T08:04:08.368060Z"
    }
   },
   "outputs": [],
   "source": [
    "if skip_training:\n",
    "    # The models are always evaluated on CPU\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FashionMNIST dataset\n",
    "\n",
    "The dataset is used is FashionMNIST. It consists of 60,000 training images of 10 classes: 'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:08.747262Z",
     "start_time": "2020-08-15T08:04:08.375058Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Transform to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Min-max scaling to [-1, 1]\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.FashionMNIST(root=data_dir, train=True, download=True, transform=transform)\n",
    "testset = torchvision.datasets.FashionMNIST(root=data_dir, train=False, download=True, transform=transform)\n",
    "\n",
    "classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal',\n",
    "           'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=5, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResNet\n",
    "\n",
    "Here I created a network with an architecure inspired by [ResNet](https://arxiv.org/pdf/1512.03385.pdf).\n",
    "\n",
    "### ResNet block\n",
    "ResNet consists of blocks with two convolutional layers and a skip connection.\n",
    "\n",
    "In the most general case, the implementation should have:\n",
    "\n",
    "<img src=\"images/resnet_block_04.png\" width=220 style=\"float: right;\">\n",
    "\n",
    "* Two convolutional layers with:\n",
    "    * 3x3 kernel\n",
    "    * no bias terms\n",
    "    * padding with one pixel on both sides\n",
    "    * 2d batch normalization after each convolutional layer.\n",
    "\n",
    "* **The first convolutional layer also (optionally) has:**\n",
    "    * different number of input channels and output channels\n",
    "    * change of the resolution with stride.\n",
    "\n",
    "* The skip connection:\n",
    "    * simply copies the input if the resolution and the number of channels do not change.\n",
    "    * if either the resolution or the number of channels change, the skip connection should have one convolutional layer with:\n",
    "        * 1x1 convolution **without bias**\n",
    "        * change of the resolution with stride (optional)\n",
    "        * different number of input channels and output channels (optional)\n",
    "    * if either the resolution or the number of channels change, the 1x1 convolutional layer is followed by 2d batch normalization.\n",
    "\n",
    "* The ReLU nonlinearity is applied after the first convolutional layer and at the end of the block.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Batch normalization is expected to be right after a convolutional layer.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/resnet_blocks_123.png\" width=650 style=\"float: top;\">\n",
    "\n",
    "The implementation should also handle specific cases such as:\n",
    "\n",
    "Left: The number of channels and the resolution do not change.\n",
    "There are no computations in the skip connection.\n",
    "\n",
    "Middle: The number of channels changes, the resolution does not change.\n",
    "\n",
    "Right: The number of channels does not change, the resolution changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:39.204304Z",
     "start_time": "2020-08-15T08:04:39.195337Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          in_channels (int):  Number of input channels.\n",
    "          out_channels (int): Number of output channels.\n",
    "          stride (int):       Controls the stride.\n",
    "        \"\"\"\n",
    "        super(Block, self).__init__()\n",
    "        self.layer1 = nn.Sequential()\n",
    "        self.layer1.add_module(\"Conv1\", nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, padding=1,stride = stride,bias = False))\n",
    "        self.layer1.add_module(\"BN1\", nn.BatchNorm2d(num_features=out_channels))# eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        self.layer1.add_module(\"Relu5\", nn.ReLU(inplace=False))\n",
    "        \n",
    "        self.layer2 = nn.Sequential()\n",
    "        self.layer2.add_module(\"Conv2\", nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3,padding=1,bias = False))\n",
    "        self.layer2.add_module(\"BN2\", nn.BatchNorm2d(num_features=out_channels))# eps=1e-05, momentum=0.1, affine=True, track_running_stats=True))\n",
    "        \n",
    "        self.shortcut = False\n",
    "        if in_channels != out_channels or stride != 1:\n",
    "            self.shortcut = nn.Sequential()\n",
    "            self.shortcut.add_module(\"Conv\", nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=1, padding=0,stride = stride,bias = False))\n",
    "            self.shortcut.add_module(\"BN\", nn.BatchNorm2d(num_features=out_channels))#\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        y = self.layer1(x)\n",
    "        y = self.layer2(y)\n",
    "        if self.shortcut:\n",
    "            x = self.shortcut(x)\n",
    "        y = F.relu(y+x)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group of blocks\n",
    "\n",
    "ResNet consists of several groups of blocks. The first block in a group may change the number of channels (often multiples the number by 2) and subsample (using strides).\n",
    "\n",
    "<img src=\"images/resnet_group.png\" width=500 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:40.309630Z",
     "start_time": "2020-08-15T08:04:40.303633Z"
    }
   },
   "outputs": [],
   "source": [
    "# implement a group of blocks\n",
    "class GroupOfBlocks(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, n_blocks, stride=1):\n",
    "        super(GroupOfBlocks, self).__init__()\n",
    "\n",
    "        first_block = Block(in_channels, out_channels, stride)\n",
    "        other_blocks = [Block(out_channels, out_channels) for _ in range(1, n_blocks)]\n",
    "        self.group = nn.Sequential(first_block, *other_blocks)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.group(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:41.148356Z",
     "start_time": "2020-08-15T08:04:41.075184Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroupOfBlocks(\n",
      "  (group): Sequential(\n",
      "    (0): Block(\n",
      "      (layer1): Sequential(\n",
      "        (Conv1): Conv2d(10, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (Relu5): ReLU()\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (Conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "      (shortcut): Sequential(\n",
      "        (Conv): Conv2d(10, 20, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (BN): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Block(\n",
      "      (layer1): Sequential(\n",
      "        (Conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (Relu5): ReLU()\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (Conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (2): Block(\n",
      "      (layer1): Sequential(\n",
      "        (Conv1): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN1): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (Relu5): ReLU()\n",
      "      )\n",
      "      (layer2): Sequential(\n",
      "        (Conv2): Conv2d(20, 20, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        (BN2): BatchNorm2d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Let's print a block\n",
    "group = GroupOfBlocks(in_channels=10, out_channels=20, n_blocks=3)\n",
    "print(group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet\n",
    "\n",
    "Next implement a ResNet with the following architecture. It contains three groups of blocks, each group having two basic blocks.\n",
    "\n",
    "<img src=\"images/resnet.png\" width=900 style=\"float: left;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:50.190925Z",
     "start_time": "2020-08-15T08:04:50.174895Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, n_blocks, n_channels=64, num_classes=10):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          n_blocks (list):   A list with three elements which contains the number of blocks in \n",
    "                             each of the three groups of blocks in ResNet.\n",
    "                             For instance, n_blocks = [2, 4, 6] means that the first group has two blocks,\n",
    "                             the second group has four blocks and the third one has six blocks.\n",
    "          n_channels (int):  Number of channels in the first group of blocks.\n",
    "          num_classes (int): Number of classes.\n",
    "        \"\"\"\n",
    "        assert len(n_blocks) == 3, \"The number of groups should be three.\"\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(n_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.group1 = GroupOfBlocks(n_channels, n_channels, n_blocks[0])\n",
    "        self.group2 = GroupOfBlocks(n_channels, 2*n_channels, n_blocks[1], stride=2)\n",
    "        self.group3 = GroupOfBlocks(2*n_channels, 4*n_channels, n_blocks[2], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=4, stride=1)\n",
    "        self.fc = nn.Linear(4*n_channels, num_classes)\n",
    "\n",
    "        # Initialize weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x, verbose=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x of shape (batch_size, 1, 28, 28): Input images.\n",
    "          verbose: True if you want to print the shapes of the intermediate variables.\n",
    "        \n",
    "        Returns:\n",
    "          y of shape (batch_size, 10): Outputs of the network.\n",
    "        \"\"\"\n",
    "        if verbose: print(x.shape)\n",
    "        x = self.conv1(x)\n",
    "        if verbose: print('conv1:  ', x.shape)\n",
    "        x = self.bn1(x)\n",
    "        if verbose: print('bn1:    ', x.shape)\n",
    "        x = self.relu(x)\n",
    "        if verbose: print('relu:   ', x.shape)\n",
    "        x = self.maxpool(x)\n",
    "        if verbose: print('maxpool:', x.shape)\n",
    "\n",
    "        x = self.group1(x)\n",
    "        if verbose: print('group1: ', x.shape)\n",
    "        x = self.group2(x)\n",
    "        if verbose: print('group2: ', x.shape)\n",
    "        x = self.group3(x)\n",
    "        if verbose: print('group3: ', x.shape)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        if verbose: print('avgpool:', x.shape)\n",
    "\n",
    "        x = x.view(-1, self.fc.in_features)\n",
    "        if verbose: print('x.view: ', x.shape)\n",
    "        x = self.fc(x)\n",
    "        if verbose: print('out:    ', x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:52.678423Z",
     "start_time": "2020-08-15T08:04:52.673423Z"
    }
   },
   "outputs": [],
   "source": [
    "# This function computes the accuracy on the test dataset\n",
    "def compute_accuracy(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:04:54.516083Z",
     "start_time": "2020-08-15T08:04:54.482082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (group1): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group2): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (Conv): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (BN): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (group3): GroupOfBlocks(\n",
       "    (group): Sequential(\n",
       "      (0): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "        (shortcut): Sequential(\n",
       "          (Conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (layer1): Sequential(\n",
       "          (Conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (Relu5): ReLU()\n",
       "        )\n",
       "        (layer2): Sequential(\n",
       "          (Conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (BN2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AvgPool2d(kernel_size=4, stride=1, padding=0)\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the network\n",
    "n_blocks = [2, 2, 2]  # number of blocks in the three groups\n",
    "net = ResNet(n_blocks, n_channels=16)\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T08:56:28.951505Z",
     "start_time": "2020-08-15T08:04:58.278575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch 0: Loss: 0.164480 Test accuracy 0.86\n",
      "Train Epoch 1: Loss: 0.160116 Test accuracy 0.88\n",
      "Train Epoch 2: Loss: 0.198986 Test accuracy 0.89\n",
      "Train Epoch 3: Loss: 0.407016 Test accuracy 0.89\n",
      "Train Epoch 4: Loss: 0.329441 Test accuracy 0.89\n",
      "Train Epoch 5: Loss: 0.117978 Test accuracy 0.91\n",
      "Train Epoch 6: Loss: 0.188071 Test accuracy 0.90\n",
      "Train Epoch 7: Loss: 0.508887 Test accuracy 0.91\n",
      "Train Epoch 8: Loss: 0.272448 Test accuracy 0.90\n",
      "Train Epoch 9: Loss: 0.089040 Test accuracy 0.91\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    optimizer = torch.optim.Adam(net.parameters(),lr=0.01)\n",
    "    n_epochs = 10\n",
    "    loss_method = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            inputs, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            net.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = loss_method(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "\n",
    "        test_accuracy = compute_accuracy(net, testloader)\n",
    "        print('Train Epoch {}: Loss: {:.6f} Test accuracy {:.2f}'.format(epoch, loss.item(), test_accuracy))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T09:17:12.635374Z",
     "start_time": "2020-08-15T09:17:09.707908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to save the model (type yes to confirm)? yes\n",
      "Model saved to 4_resnet.pth.\n"
     ]
    }
   ],
   "source": [
    "if not skip_training:\n",
    "    tools.save_model(net, '4_resnet.pth')\n",
    "else:\n",
    "    net = ResNet(n_blocks, n_channels=16)\n",
    "    tools.load_model(net, '4_resnet.pth', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-15T09:17:33.827893Z",
     "start_time": "2020-08-15T09:17:15.003346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test images: 0.914\n"
     ]
    }
   ],
   "source": [
    "# Compute the accuracy on the test set\n",
    "accuracy = compute_accuracy(net, testloader)\n",
    "print('Accuracy of the network on the test images: %.3f' % accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
